{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQN_project_MVA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4b15c03574f74cc8a455fa2b712bccb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_36f804a820df4e7b83a460db1f0113a0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_549edf6c1dc246e18a30be96e53f67d7",
              "IPY_MODEL_14f6f5ec67ac4fc89651508ff25cc1eb"
            ]
          }
        },
        "36f804a820df4e7b83a460db1f0113a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "549edf6c1dc246e18a30be96e53f67d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_02fedc51834540ab940e9ecabe93e058",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 11,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 11,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5e965854656d4be9bc440f1524abbf70"
          }
        },
        "14f6f5ec67ac4fc89651508ff25cc1eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_25a5e5ee1b974ca3ab4403eeb368ef9d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 11/11 [01:04&lt;00:00,  5.92s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_287742c50bb8453f9bb595dcab1bd4fa"
          }
        },
        "02fedc51834540ab940e9ecabe93e058": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5e965854656d4be9bc440f1524abbf70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "25a5e5ee1b974ca3ab4403eeb368ef9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "287742c50bb8453f9bb595dcab1bd4fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "599c4fd3381f41179b775ca279adcd70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d7f756dbd71144ad98b85c72d855454e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_80b4470eceaf428889e858c9b8c79896",
              "IPY_MODEL_4fd898bf1a0348a594d7c97695e5c180"
            ]
          }
        },
        "d7f756dbd71144ad98b85c72d855454e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "80b4470eceaf428889e858c9b8c79896": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_31fb4461baf84626b9675a28761a350e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 11,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 11,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7cca43208bcc4174992875a13c3f11e0"
          }
        },
        "4fd898bf1a0348a594d7c97695e5c180": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_250e1d09f2904415acc0c4f2c2785ea2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 11/11 [01:27&lt;00:00,  8.01s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f9e24a9b7d994c4297acb7c2f46890d2"
          }
        },
        "31fb4461baf84626b9675a28761a350e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7cca43208bcc4174992875a13c3f11e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "250e1d09f2904415acc0c4f2c2785ea2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f9e24a9b7d994c4297acb7c2f46890d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f9a1e45c96e44ebe94d079108c6ab428": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0cc050f66a0b4b08a12ff404a6a689fa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_522d456c9df0421b9129887e8badc1a9",
              "IPY_MODEL_05e35b38341744e3abd7f0fddf120392"
            ]
          }
        },
        "0cc050f66a0b4b08a12ff404a6a689fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "522d456c9df0421b9129887e8badc1a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9ad75421d67f435c935b823f3ef418bd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 21,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 21,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e1e349338807414d89804c379e5d5e49"
          }
        },
        "05e35b38341744e3abd7f0fddf120392": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_52af348165b94a31b30303270dc29b7a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 21/21 [02:44&lt;00:00,  7.84s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cb57c1f4dbfe4f3abd06994e7414b176"
          }
        },
        "9ad75421d67f435c935b823f3ef418bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e1e349338807414d89804c379e5d5e49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "52af348165b94a31b30303270dc29b7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cb57c1f4dbfe4f3abd06994e7414b176": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OH0f011iN80u"
      },
      "source": [
        "**You may need to install [OpenCV](https://pypi.python.org/pypi/opencv-python) and [scikit-video](http://www.scikit-video.org/stable/).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Cs26z1IEOBfH",
        "outputId": "8c395ccf-ae7e-40a2-dcf1-c6a716ffe225",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "!pip install scikit-video"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-video\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/a6/c69cad508139a342810ae46e946ebb3256aa6e42f690d901bb68f50582e3/scikit_video-1.1.11-py2.py3-none-any.whl (2.3MB)\n",
            "\r\u001b[K     |▏                               | 10kB 15.1MB/s eta 0:00:01\r\u001b[K     |▎                               | 20kB 3.3MB/s eta 0:00:01\r\u001b[K     |▍                               | 30kB 4.7MB/s eta 0:00:01\r\u001b[K     |▋                               | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |▊                               | 51kB 3.7MB/s eta 0:00:01\r\u001b[K     |▉                               | 61kB 4.4MB/s eta 0:00:01\r\u001b[K     |█                               | 71kB 5.1MB/s eta 0:00:01\r\u001b[K     |█▏                              | 81kB 5.7MB/s eta 0:00:01\r\u001b[K     |█▎                              | 92kB 6.3MB/s eta 0:00:01\r\u001b[K     |█▌                              | 102kB 4.9MB/s eta 0:00:01\r\u001b[K     |█▋                              | 112kB 4.9MB/s eta 0:00:01\r\u001b[K     |█▊                              | 122kB 4.9MB/s eta 0:00:01\r\u001b[K     |██                              | 133kB 4.9MB/s eta 0:00:01\r\u001b[K     |██                              | 143kB 4.9MB/s eta 0:00:01\r\u001b[K     |██▏                             | 153kB 4.9MB/s eta 0:00:01\r\u001b[K     |██▎                             | 163kB 4.9MB/s eta 0:00:01\r\u001b[K     |██▌                             | 174kB 4.9MB/s eta 0:00:01\r\u001b[K     |██▋                             | 184kB 4.9MB/s eta 0:00:01\r\u001b[K     |██▊                             | 194kB 4.9MB/s eta 0:00:01\r\u001b[K     |███                             | 204kB 4.9MB/s eta 0:00:01\r\u001b[K     |███                             | 215kB 4.9MB/s eta 0:00:01\r\u001b[K     |███▏                            | 225kB 4.9MB/s eta 0:00:01\r\u001b[K     |███▍                            | 235kB 4.9MB/s eta 0:00:01\r\u001b[K     |███▌                            | 245kB 4.9MB/s eta 0:00:01\r\u001b[K     |███▋                            | 256kB 4.9MB/s eta 0:00:01\r\u001b[K     |███▉                            | 266kB 4.9MB/s eta 0:00:01\r\u001b[K     |████                            | 276kB 4.9MB/s eta 0:00:01\r\u001b[K     |████                            | 286kB 4.9MB/s eta 0:00:01\r\u001b[K     |████▏                           | 296kB 4.9MB/s eta 0:00:01\r\u001b[K     |████▍                           | 307kB 4.9MB/s eta 0:00:01\r\u001b[K     |████▌                           | 317kB 4.9MB/s eta 0:00:01\r\u001b[K     |████▋                           | 327kB 4.9MB/s eta 0:00:01\r\u001b[K     |████▉                           | 337kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 348kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 358kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 368kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 378kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 389kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 399kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 409kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 419kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 430kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 440kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 450kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 460kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 471kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 481kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 491kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 501kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 512kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 522kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 532kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 542kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 552kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 563kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 573kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 583kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 593kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 604kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 614kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 624kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 634kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 645kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 655kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 665kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 675kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 686kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 696kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████                      | 706kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 716kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 727kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 737kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 747kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 757kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 768kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 778kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 788kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 798kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 808kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 819kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 829kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 839kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 849kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 860kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 870kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 880kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 890kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 901kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 911kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 921kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 931kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 942kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 952kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 962kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 972kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 983kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 993kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 1.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 1.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 1.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 1.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 1.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.4MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.4MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.4MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.4MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.4MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.4MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.4MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.4MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.4MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.4MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.5MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.5MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.5MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.5MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.5MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.5MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.5MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.5MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.5MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.5MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.6MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.6MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.6MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.6MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.6MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.6MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.6MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.6MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.6MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.6MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.7MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.7MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.7MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.7MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.7MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.7MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.7MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.7MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.7MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.8MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.8MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.8MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.8MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.8MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.8MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.8MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.8MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.8MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.8MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.9MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.9MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.9MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.9MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.9MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.9MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.9MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.9MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.9MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.9MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 2.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 2.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 2.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 2.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 2.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 2.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 2.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 2.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 2.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 2.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 2.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 2.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 2.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 2.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 2.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 2.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 2.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 2.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 2.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 2.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 2.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 2.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 2.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 2.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 2.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 2.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 2.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.3MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.3MB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from scikit-video) (1.17.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from scikit-video) (1.4.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from scikit-video) (6.2.2)\n",
            "Installing collected packages: scikit-video\n",
            "Successfully installed scikit-video-1.1.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_PQW2LahN802",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "279abbda-f610-473b-bf99-0779f849a083"
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "import skvideo.io\n",
        "import cv2\n",
        "import json\n",
        "import random\n",
        "import tqdm as tqdm\n",
        "\n",
        "from keras.models import Sequential, model_from_json\n",
        "from keras.layers.core import Dense, Dropout\n",
        "from keras.optimizers import sgd, adam\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, AveragePooling2D, Reshape, BatchNormalization, Flatten"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S79YmMnc5Lrh",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\") # only if needed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ISppyWUIN81Q"
      },
      "source": [
        "# MiniProject on Deep Reinforcement Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XmSFBK7pN81V"
      },
      "source": [
        "__Notations__: $E_p$ is the expectation under probability $p$. Please justify each of your answer and widely comment your code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EUuEteCiN81Z"
      },
      "source": [
        "# Context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Nh6WXl58N81f"
      },
      "source": [
        "In a reinforcement learning algorithm, we modelize each step $t$ as an action $a_t$ obtained from a state $s_t$, i.e. $\\{(a_{t},s_{t})_{t\\leq T}\\}$ having the Markov property. We consider a discount factor $\\gamma \\in [0,1]$ that ensures convergence. The goal is to find among all the policies $\\pi$, one that maximizes the expected reward:\n",
        "\n",
        "\\begin{equation*}\n",
        "R(\\pi)=\\sum_{t\\leq T}E_{p^{\\pi}}[\\gamma^t r(s_{t},a_{t})] \\> ,\n",
        "\\end{equation*}\n",
        "\n",
        "where: \n",
        "\\begin{equation*}p^{\\pi}(a_{0},a_{1},s_{1},...,a_{T},s_{T})=p(a_{0})\\prod_{t=1}^{T}\\pi(a_{t}|s_{t})p(s_{t+1}|s_{t},a_{t}) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "We note the $Q$-function:\n",
        "\n",
        "\\begin{equation*}Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "Thus, the optimal Q function is:\n",
        "\\begin{equation*}\n",
        "Q^*(s,a)=\\max_{\\pi}Q^\\pi(s,a) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "In this project, we will apply the deep reinforcement learning techniques to a simple game: an agent will have to learn from scratch a policy that will permit it maximizing a reward."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8RF-COsLN81h"
      },
      "source": [
        "## The environment, the agent and the game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YFwO_48UN81k"
      },
      "source": [
        "### The environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ou35Q6NeN81r"
      },
      "source": [
        "```Environment``` is an abstract class that represents the states, rewards, and actions to obtain the new state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HA_RK8bGN81v",
        "colab": {}
      },
      "source": [
        "class Environment(object):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def act(self, act):\n",
        "        \"\"\"\n",
        "        One can act on the environment and obtain its reaction:\n",
        "        - the new state\n",
        "        - the reward of the new state\n",
        "        - should we continue the game?\n",
        "\n",
        "        :return: state, reward, game_over\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Reinitialize the environment to a random state and returns\n",
        "        the original state\n",
        "\n",
        "        :return: state\n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    def draw(self):\n",
        "        \"\"\"\n",
        "        Visualize in the console or graphically the current state\n",
        "        \"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hgTFv8h-N818"
      },
      "source": [
        "The method ```act``` allows to act on the environment at a given state $s_t$ (stored internally), via action $a_t$. The method will return the new state $s_{t+1}$, the reward $r(s_{t},a_{t})$ and determines if $t\\leq T$ (*game_over*).\n",
        "\n",
        "The method ```reset``` simply reinitializes the environment to a random state $s_0$.\n",
        "\n",
        "The method ```draw``` displays the current state $s_t$ (this is useful to check the behavior of the Agent).\n",
        "\n",
        "We modelize $s_t$ as a tensor, while $a_t$ is an integer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0pScmDf2N82B"
      },
      "source": [
        "### The Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C6m3v8yoN82F"
      },
      "source": [
        "The goal of the ```Agent``` is to interact with the ```Environment``` by proposing actions $a_t$ obtained from a given state $s_t$ to attempt to maximize its __reward__ $r(s_t,a_t)$. We propose the following abstract class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RXwuCF4mN82I",
        "colab": {}
      },
      "source": [
        "class Agent(object):\n",
        "    def __init__(self, epsilon=0.1, n_action=4):\n",
        "        self.epsilon = epsilon\n",
        "        self.n_action = n_action\n",
        "    \n",
        "    def set_epsilon(self,e):\n",
        "        self.epsilon = e\n",
        "\n",
        "    def act(self,s,train=True):\n",
        "        \"\"\" This function should return the next action to do:\n",
        "        an integer between 0 and 4 (not included) with a random exploration of epsilon\"\"\"\n",
        "        if train:\n",
        "            if np.random.rand() <= self.epsilon:\n",
        "                a = np.random.randint(0, self.n_action, size=1)[0]\n",
        "            else:\n",
        "                a = self.learned_act(s)\n",
        "        else: # in some cases, this can improve the performance.. remove it if poor performances\n",
        "            a = self.learned_act(s)\n",
        "\n",
        "        return a\n",
        "\n",
        "    def learned_act(self,s):\n",
        "        \"\"\" Act via the policy of the agent, from a given state s\n",
        "        it proposes an action a\"\"\"\n",
        "        pass\n",
        "\n",
        "    def reinforce(self, s, n_s, a, r, game_over_):\n",
        "        \"\"\" This function is the core of the learning algorithm. \n",
        "        It takes as an input the current state s_, the next state n_s_\n",
        "        the action a_ used to move from s_ to n_s_ and the reward r_.\n",
        "        \n",
        "        Its goal is to learn a policy.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def save(self):\n",
        "        \"\"\" This function returns basic stats if applicable: the\n",
        "        loss and/or the model\"\"\"\n",
        "        pass\n",
        "\n",
        "    def load(self):\n",
        "        \"\"\" This function allows to restore a model\"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M1baFVzQN82S"
      },
      "source": [
        "***\n",
        "__Question 1__:\n",
        "Explain the function act. Why is ```epsilon``` essential?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NKMVS2T9N82U"
      },
      "source": [
        "Given a state `s`, the `act` function will return the action to take. But here we will not return our best action everytime (learned from the past), instead thanks to `epsilon` (the exploration parameter) we will take sometime (with probability `epsilon`) a random action. This parameter `epsilon` is essential in order to explore other options and also to try to get out of a local minima."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RqUG45FjN82Y"
      },
      "source": [
        "***\n",
        "### The Game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YR06BXpcN82b"
      },
      "source": [
        "The ```Agent``` and the ```Environment``` work in an interlaced way as in the following (take some time to understand this code as it is the core of the project)\n",
        "\n",
        "```python\n",
        "\n",
        "epoch = 300\n",
        "env = Environment()\n",
        "agent = Agent()\n",
        "\n",
        "\n",
        "# Number of won games\n",
        "score = 0\n",
        "loss = 0\n",
        "\n",
        "\n",
        "for e in range(epoch):\n",
        "    # At each epoch, we restart to a fresh game and get the initial state\n",
        "    state = env.reset()\n",
        "    # This assumes that the games will end\n",
        "    game_over = False\n",
        "\n",
        "    win = 0\n",
        "    lose = 0\n",
        "    \n",
        "    while not game_over:\n",
        "        # The agent performs an action\n",
        "        action = agent.act(state)\n",
        "\n",
        "        # Apply an action to the environment, get the next state, the reward\n",
        "        # and if the games end\n",
        "        prev_state = state\n",
        "        state, reward, game_over = env.act(action)\n",
        "\n",
        "        # Update the counters\n",
        "        if reward > 0:\n",
        "            win = win + reward\n",
        "        if reward < 0:\n",
        "            lose = lose -reward\n",
        "\n",
        "        # Apply the reinforcement strategy\n",
        "        loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "    # Save as a mp4\n",
        "    if e % 10 == 0:\n",
        "        env.draw(e)\n",
        "\n",
        "    # Update stats\n",
        "    score += win-lose\n",
        "\n",
        "    print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "          .format(e, epoch, loss, win, lose, win-lose))\n",
        "    agent.save()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I8uZdWL4N82e"
      },
      "source": [
        "# The game, *eat cheese*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ny7y6SteN82h"
      },
      "source": [
        "A rat runs on an island and tries to eat as much as possible. The island is subdivided into $N\\times N$ cells, in which there are cheese (+0.5) and poisonous cells (-1). The rat has a visibility of 2 cells (thus it can see $5^2$ cells). The rat is given a time $T$ to accumulate as much food as possible. It can perform 4 actions: going up, down, left, right. \n",
        "\n",
        "The goal is to code an agent to solve this task that will learn by trial and error. We propose the following environment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zZq8g2_hN82k",
        "colab": {}
      },
      "source": [
        "class Environment(object):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        grid_size = grid_size + 4 # just extend so we can code the borders (limits of the env.)\n",
        "        self.grid_size = grid_size # save the grid size\n",
        "        self.max_time = max_time # T, how much time before the game is over\n",
        "        self.temperature = temperature # probability of having a cheese, poison \"in a given cell\"\n",
        "\n",
        "        #board on which one plays\n",
        "        self.board = np.zeros((grid_size, grid_size)) # stores the bonus/malus (and so the cheese/poison positions): reward\n",
        "        self.position = np.zeros((grid_size, grid_size)) # the board (what the rat sees/ where is the rat/borders)\n",
        "\n",
        "        # coordinate of the rat\n",
        "        self.x = 0 # starting position x\n",
        "        self.y = 1 # starting position y\n",
        "\n",
        "        # self time\n",
        "        self.t = 0 # initialize the time t=0\n",
        "\n",
        "        self.scale = 16 # scale factor along the vertical axis (OpenCV)\n",
        "\n",
        "        self.to_draw = np.zeros((max_time + 2, grid_size * self.scale, grid_size * self.scale, 3)) # for the video\n",
        "\n",
        "\n",
        "    def draw(self, e):\n",
        "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw) # display the video (e: look for the number of epoch)\n",
        "\n",
        "    def get_frame(self, t):\n",
        "        b = np.zeros((self.grid_size, self.grid_size, 3)) + 128 # neutral cells are grey (128, 128, 128) in rgb\n",
        "        b[self.board > 0, 0] = 255 # cheese cells are yellow (255, 255, 0) in rgb\n",
        "        b[self.board > 0, 1] = 255 # cheese cells are yellow (255, 255, 0) in rgb\n",
        "        b[self.board > 0, 2] = 0 # cheese cells are yellow (255, 255, 0) in rgb\n",
        "        b[self.board < 0, 0] = 255 # poison cells are red (255, 0, 0) in rgb\n",
        "        b[self.board < 0, 1] = 0 # poison cells are red (255, 0, 0) in rgb\n",
        "        b[self.board < 0, 2] = 0 # poison cells are red (255, 0, 0) in rgb\n",
        "        b[self.x, self.y, 0] = 0 # rat's position is green (0, 128, 0) in rgb\n",
        "        b[self.x, self.y, 2] = 0 # rat's position is green (0, 128, 0) in rgb\n",
        "        b[self.x, self.y, 1] = 128 # rat's position is green (0, 128, 0) in rgb\n",
        "        b[-2:, :, :] = 0 # limit of the board is black\n",
        "        b[:, -2:, :] = 0 # limit of the board is black\n",
        "        b[:2, :, :] = 0 # limit of the board is black\n",
        "        b[:, :2, :] = 0 # limit of the board is black\n",
        "        \n",
        "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        self.to_draw[t, :, :, :] = b # save the frame\n",
        "\n",
        "\n",
        "    def act(self, action):\n",
        "        \"\"\"This function returns the new state, reward and decides if the\n",
        "        game ends.\"\"\"\n",
        "\n",
        "        self.get_frame(int(self.t)) # stores the frame at time t\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size)) # the board (what the rat sees/ where is the rat/borders)\n",
        "\n",
        "        \n",
        "                                     ## -1 -1 -1 -1 -1 -1 -1 -1\n",
        "                                     ## -1 -1 -1 -1 -1 -1 -1 -1\n",
        "        self.position[0:2, :] = -1   ## -1 -1  ok  ok ok  -1 -1\n",
        "        self.position[:, 0:2] = -1   ## -1 -1  ok  ok ok  -1 -1\n",
        "        self.position[-2:, :] = -1   ## -1 -1  ok  ok ok  -1 -1\n",
        "        self.position[:, -2:] = -1   ## -1 -1  ok  ok ok  -1 -1\n",
        "                                     ## -1 -1 -1 -1 -1 -1 -1 -1\n",
        "                                     ## -1 -1 -1 -1 -1 -1 -1 -1\n",
        "\n",
        "\n",
        "        self.position[self.x, self.y] = 1 # 1 where is the rat\n",
        "        if action == 0: # right\n",
        "            if self.x == self.grid_size - 3: # if on the last column\n",
        "                self.x = self.x-1 # we go to the left\n",
        "            else:\n",
        "                self.x = self.x + 1 # we go the right\n",
        "        elif action == 1: # left\n",
        "            if self.x == 2: # if on the 2th column\n",
        "                self.x = self.x+1 # we go to the right\n",
        "            else:\n",
        "                self.x = self.x-1 # we go to the left\n",
        "        elif action == 2: # down\n",
        "            if self.y == self.grid_size - 3: # if on the last row\n",
        "                self.y = self.y - 1 # we go up\n",
        "            else:\n",
        "                self.y = self.y + 1 # we go down\n",
        "        elif action == 3: # up\n",
        "            if self.y == 2: # if on the 2th row\n",
        "                self.y = self.y + 1 # we go down\n",
        "            else:\n",
        "                self.y = self.y - 1 # we go up\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized') \n",
        "\n",
        "        self.t = self.t + 1 # update the time\n",
        "        reward = self.board[self.x, self.y] # reward defines by the position\n",
        "        self.board[self.x, self.y] = 0 # we reset the reward at our position (we ate the poison/cheese)\n",
        "        game_over = self.t > self.max_time # game is over if t > T\n",
        "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size, 1), # state of the game (board, position)\n",
        "                                self.position.reshape(self.grid_size, self.grid_size, 1)), axis=2)\n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :] # we can only see the area around the rat (5 * 5)\n",
        "        return state, reward, game_over\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "        ### initialize a random position for the rat\n",
        "        self.x = np.random.randint(3, self.grid_size - 3)\n",
        "        self.y = np.random.randint(3, self.grid_size - 3)\n",
        "\n",
        "        ### initialize the cheese\n",
        "        bonus = 0.5 * np.random.binomial(1, self.temperature, size=self.grid_size ** 2)\n",
        "        bonus = bonus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        ### initialize the poison\n",
        "        malus = - 1.0 * np.random.binomial(1, self.temperature, size=self.grid_size ** 2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        ### clipboard animation initialization\n",
        "        self.to_draw = np.zeros((self.max_time + 2, self.grid_size * self.scale, self.grid_size * self.scale, 3))\n",
        "\n",
        "        ### if a cheese overlap with a poison we let the cheese and cancel the poison\n",
        "        malus[bonus > 0] = 0\n",
        "\n",
        "        ### construct the final board using the bonus (cheese) and malus (poison)\n",
        "        self.board = bonus + malus\n",
        "\n",
        "        ### initialize the position\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2, :]= -1\n",
        "        self.position[:, 0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[:, -2:] = -1\n",
        "\n",
        "        ###  initialize the position of the rat (he eats the cheese or the poison!)\n",
        "        self.board[self.x, self.y] = 0\n",
        "\n",
        "        ### initialize the time\n",
        "        self.t = 0\n",
        "\n",
        "        ### construct the state using (board, position)\n",
        "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.position.reshape(self.grid_size, self.grid_size,1)),\n",
        "                               axis=2)\n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :] # we only see 5 * 5 around the (self.x, self.y)\n",
        "        return state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m3fzfCiNN82v"
      },
      "source": [
        "The following elements are important because they correspond to the hyper parameters for this project:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ceqsjC5tN82y",
        "colab": {}
      },
      "source": [
        "# parameters\n",
        "size = 13 # grid size\n",
        "T = 200 # how much time before the game is over\n",
        "temperature = 0.3 # probability of having a cheese/poison at a specific location\n",
        "epochs_train = 10 # set small when debugging\n",
        "epochs_test = 10 # set small when debugging\n",
        "\n",
        "# display videos\n",
        "def display_videos(name):\n",
        "    video = io.open(name, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    return '''<video alt=\"test\" controls>\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VHm5XyenN83B"
      },
      "source": [
        "__Question 2__ Explain the use of the arrays ```position``` and ```board```."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vIK4trJzN83F"
      },
      "source": [
        "With `position` we store the board (limits of the environment) and we use it in order to move the rat. In the other hand `board` is used to store the reward (bonus/malus) and we use it when the rat eats."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xRlViMooN83H"
      },
      "source": [
        "## Random Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fEXZ6zS1N83L"
      },
      "source": [
        "***\n",
        "__Question 3__ Implement a random Agent (only ```learned_act``` needs to be implemented):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OopgcqizN83P",
        "colab": {}
      },
      "source": [
        "class RandomAgent(Agent):\n",
        "    def __init__(self):\n",
        "        super(RandomAgent, self).__init__()\n",
        "        pass\n",
        "\n",
        "    def learned_act(self, s):\n",
        "        return np.random.choice(4) # choose uniformly in {1, 2, 3, 4}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b8L4VPh0N83Z"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 4__ Visualize the game moves. You need to fill in the following function for the evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dFnWAgOwN83n",
        "colab": {}
      },
      "source": [
        "def test(agent, env, epochs, prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    \n",
        "    for e in range(epochs):\n",
        "        \n",
        "        ##### FILL IN HERE\n",
        "        state = env.reset() # first reset the environment\n",
        "        game_over = False # initialize 'game_over'\n",
        "        win, lose = 0, 0 # initialize win/lose\n",
        "        while not game_over: # loop while it's not over\n",
        "            if prefix == 'random':\n",
        "                action = agent.learned_act(state) # take action with the agent\n",
        "            elif prefix == 'cnn_test_explore':\n",
        "                action = agent.learned_act(state.flatten().reshape(1, 5, 5, 3)) # take action with the agent\n",
        "            elif prefix == 'fc_train':\n",
        "                action = agent.learned_act(state.flatten().reshape(1, -1)) # take action with the agent\n",
        "            else:\n",
        "                action = agent.learned_act(state.reshape(1, 5, 5, 2)) # take action with the agent\n",
        "            \n",
        "            if prefix == 'cnn_test_explore':\n",
        "                state, reward, game_over = env.act(action, train=False) # update the env. with the action\n",
        "            else:\n",
        "                state, reward, game_over = env.act(action) # update the env. with the action\n",
        "            if reward > 0: # update win/lose\n",
        "                win += reward\n",
        "            else:\n",
        "                lose -= reward\n",
        "\n",
        "        # Save as a mp4\n",
        "        env.draw(prefix + str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score = score + win - lose\n",
        "\n",
        "        print(f\"Epoch {e}, win/lose count {win}/{lose}, average score ({np.round(score / (1 + e), 2)})\")\n",
        "    print(f'Final score: {score / epochs}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o0kK7GqHN83x",
        "outputId": "33b0ba9b-2e46-42da-a0e5-3840e835ebfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "source": [
        "# Initialize the game\n",
        "env = Environment(grid_size=size, max_time=T, temperature=temperature)\n",
        "\n",
        "# Initialize the agent!\n",
        "agent = RandomAgent()\n",
        "\n",
        "# run the agent\n",
        "test(agent, env, epochs_test, prefix='random')\n",
        "\n",
        "# display the result\n",
        "print(\"\\nCheese in yellow and poison in red\")\n",
        "HTML(display_videos('random0.mp4')) # don't need to look other videos since it is random"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, win/lose count 10.0/13.0, average score (-3.0)\n",
            "Epoch 1, win/lose count 13.0/7.0, average score (1.5)\n",
            "Epoch 2, win/lose count 7.0/14.0, average score (-1.33)\n",
            "Epoch 3, win/lose count 5.5/11.0, average score (-2.38)\n",
            "Epoch 4, win/lose count 9.5/9.0, average score (-1.8)\n",
            "Epoch 5, win/lose count 10.5/16.0, average score (-2.42)\n",
            "Epoch 6, win/lose count 10.0/13.0, average score (-2.5)\n",
            "Epoch 7, win/lose count 12.5/10.0, average score (-1.88)\n",
            "Epoch 8, win/lose count 14.5/15.0, average score (-1.72)\n",
            "Epoch 9, win/lose count 7.5/13.0, average score (-2.1)\n",
            "Final score: -2.1\n",
            "\n",
            "Cheese in yellow and poison in red\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X5L_gfNVN836"
      },
      "source": [
        "***\n",
        "## DQN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "p9jHu2HaN83-"
      },
      "source": [
        "Let us assume here that $T=\\infty$.\n",
        "\n",
        "***\n",
        "__Question 5__ Let $\\pi$ be a policy, show that:\n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
        "\\end{equation*}\n",
        "\n",
        "Then, show that for the optimal policy $\\pi^*$ (we assume its existence), the following holds: \n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
        "\\end{equation*}\n",
        "Finally, deduce that a plausible objective is:\n",
        "\n",
        "\\begin{equation*}\n",
        "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
        "\\end{equation*}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFSTpy0SsE85",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NDFZ8a-nN84D"
      },
      "source": [
        "***\n",
        "The DQN-learning algorithm relies on these derivations to train the parameters $\\theta$ of a Deep Neural Network:\n",
        "\n",
        "1. At the state $s_t$, select the action $a_t$ with best reward using $Q_t$ and store the results;\n",
        "\n",
        "2. Obtain the new state $s_{t+1}$ from the environment $p$;\n",
        "\n",
        "3. Store $(s_t,a_t,s_{t+1})$;\n",
        "\n",
        "4. Obtain $Q_{t+1}$ by minimizing  $\\mathcal{L}$ from a recovered batch from the previously stored results.\n",
        "\n",
        "***\n",
        "__Question 6__ Implement the class ```Memory``` that stores moves (in a replay buffer) via ```remember``` and provides a ```random_access``` to these. Specify a maximum memory size to avoid side effects. You can for example use a ```list()``` and set by default ```max_memory=100```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jAK2wF5tN84E",
        "colab": {}
      },
      "source": [
        "class Memory(object):\n",
        "    def __init__(self, max_memory=100):\n",
        "        self.max_memory = max_memory # maximum elements stored\n",
        "        self.memory = list() # initialize the memory\n",
        "\n",
        "    def remember(self, m):\n",
        "        if len(self.memory) <= self.max_memory: # if not full\n",
        "            self.memory.append(m) # store element m at the end\n",
        "        else:\n",
        "            self.memory = self.memory[1:] # remove the first element\n",
        "            self.memory.append(m) # store element m at the end\n",
        "\n",
        "    def random_access(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size) # random sample, from memory, of size batch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SIkR03LpN84K"
      },
      "source": [
        "***\n",
        "The pipeline we will use for training is given below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LfheCQXfN84M",
        "colab": {}
      },
      "source": [
        "def train(agent, env, epoch, prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "\n",
        "    for e in tqdm.tqdm_notebook(range(epoch)):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "\n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            if prefix == 'fc_train':\n",
        "                action = agent.learned_act(state.flatten().reshape(1, -1)) # take action with the agent\n",
        "            else:\n",
        "                action = agent.learned_act(state.reshape(1, 5, 5, 2)) # take action with the agent\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose - reward\n",
        "\n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over, prefix)\n",
        "        \n",
        "\n",
        "        # Save as a mp4\n",
        "        if e % 10 == 0:\n",
        "            env.draw(prefix + str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win - lose\n",
        "\n",
        "        print(f\"Epoch {e}/{epoch}, loss {round(np.float64(loss), 4)}, win/lose count {win}/{lose} ({win - lose})\")\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mL8rvPzRN84V"
      },
      "source": [
        "***\n",
        "__Question 7__ Implement the DQN training algorithm using a cascade of fully connected layers. You can use different learning rate, batch size or memory size parameters. In particular, the loss might oscillate while the player will start to win the games. You have to find a good criterium."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Tmj5qFqSN84X",
        "colab": {}
      },
      "source": [
        "class DQN(Agent):\n",
        "    def __init__(self, grid_size,  epsilon=0.1, memory_size=100, batch_size=16, n_state=2):\n",
        "        super(DQN, self).__init__(epsilon=epsilon)\n",
        "        self.epsilon = epsilon \n",
        "\n",
        "        # Discount for Q learning (gamma)\n",
        "        self.discount = 0.99\n",
        "        \n",
        "        self.grid_size = grid_size\n",
        "        \n",
        "        # number of state\n",
        "        self.n_state = n_state\n",
        "\n",
        "        # Memory\n",
        "        self.memory = Memory(memory_size)\n",
        "        \n",
        "        # Batch size when learning\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def learned_act(self, s):\n",
        "        if np.random.rand() > self.epsilon: # epsilon exploration strategy\n",
        "            return np.argmax(agent.model.predict(s), axis=1) # our best action\n",
        "        else:\n",
        "            return np.random.choice(4) # random action\n",
        "\n",
        "    def reinforce(self, state, next_state, action, reward, game_over, prefix):\n",
        "        ### Two steps: first memorize the states, second learn from the pool\n",
        "        ### 1) memorize\n",
        "        self.memory.remember([state, next_state, action, reward, game_over])\n",
        "\n",
        "        ### 2) learn from the pool\n",
        "        input_states = np.zeros((self.batch_size, 5, 5, self.n_state))\n",
        "        target_q = np.zeros((self.batch_size, 4))\n",
        "\n",
        "        if len(self.memory.memory) < self.batch_size: # if not enaugh elements in memory we do nothing\n",
        "            return 1e5 # unknow (loss)\n",
        "        \n",
        "        samples =  self.memory.random_access(self.batch_size) # random samples from the memory\n",
        "        for i in range(self.batch_size):\n",
        "            \n",
        "            ### get elements from memory[i]\n",
        "            input_states[i], next_s, a, r, end = samples[i] # state, next_state, action, reward, game_over\n",
        "                \n",
        "            ### update the target\n",
        "            if end:\n",
        "                target_q[i, a] = r \n",
        "            else:\n",
        "                ### compute max_a Q(nex_state, a) using the model\n",
        "                if prefix == 'fc_train':\n",
        "                    Q_next_state = np.max(agent.model.predict(next_s.flatten().reshape(1, -1)))\n",
        "                elif prefix == 'cnn_train_explore':\n",
        "                    Q_next_state = np.max(agent.model.predict(next_s.flatten().reshape(1, 5, 5, 3)))\n",
        "                else:\n",
        "                    Q_next_state = np.max(agent.model.predict(next_s.reshape(1, 5, 5, 2)))\n",
        "                    \n",
        "                ### r + gamma * max_a Q(nex_state, a)\n",
        "                target_q[i, a] = r + self.discount * Q_next_state\n",
        "\n",
        "        # HINT: Clip the target to avoid exploiding gradients.. -- clipping is a bit tighter\n",
        "        target_q = np.clip(target_q, -3, 3)\n",
        "\n",
        "        ### train the model on the batch\n",
        "        if prefix == 'fc_train':\n",
        "            input_data = np.array([input_states[i].flatten().reshape(-1) for i in range(self.batch_size)])\n",
        "            loss = self.model.train_on_batch(input_data, target_q)\n",
        "        elif prefix == 'cnn_train_explore':\n",
        "            input_data = np.array([input_states[i].flatten().reshape(5, 5, 3) for i in range(self.batch_size)])\n",
        "            loss = self.model.train_on_batch(input_data, target_q)\n",
        "        else:\n",
        "            input_data = np.array([input_states[i].reshape(5, 5, 2) for i in range(self.batch_size)]) \n",
        "            loss = self.model.train_on_batch(input_data, target_q)\n",
        "            \n",
        "        return loss\n",
        "\n",
        "    def save(self,name_weights='model.h5',name_model='model.json'):\n",
        "        self.model.save_weights(name_weights, overwrite=True)\n",
        "        with open(name_model, \"w\") as outfile:\n",
        "            json.dump(self.model.to_json(), outfile)\n",
        "            \n",
        "    def load(self,name_weights='model.h5',name_model='model.json'):\n",
        "        with open(name_model, \"r\") as jfile:\n",
        "            model = model_from_json(json.load(jfile))\n",
        "        model.load_weights(name_weights)\n",
        "        model.compile(\"sgd\", \"mse\")\n",
        "        self.model = model\n",
        "\n",
        "            \n",
        "class DQN_FC(DQN):\n",
        "    def __init__(self, *args, lr=0.1, **kwargs):\n",
        "        super(DQN_FC, self).__init__( *args, **kwargs)\n",
        "        \n",
        "        ### NN Model\n",
        "        model = Sequential() \n",
        "\n",
        "        #Input layer\n",
        "        model.add(Dense(units=200, input_dim=50, activation='relu'))\n",
        "        model.add(Dropout(0.25))\n",
        "\n",
        "        #Hidden layer 1\n",
        "        model.add(Dense(units=200, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "\n",
        "        #Output layer\n",
        "        model.add(Dense(units=4, activation=None))\n",
        "        \n",
        "        ####### FILL IN\n",
        "        \n",
        "        model.compile(adam(lr=lr), \"mse\")\n",
        "        self.model = model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "collapsed": true,
        "id": "nEmtWMe8N84f",
        "outputId": "544681d7-7c12-4123-c54a-f833d041828c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4b15c03574f74cc8a455fa2b712bccb2",
            "36f804a820df4e7b83a460db1f0113a0",
            "549edf6c1dc246e18a30be96e53f67d7",
            "14f6f5ec67ac4fc89651508ff25cc1eb",
            "02fedc51834540ab940e9ecabe93e058",
            "5e965854656d4be9bc440f1524abbf70",
            "25a5e5ee1b974ca3ab4403eeb368ef9d",
            "287742c50bb8453f9bb595dcab1bd4fa"
          ]
        }
      },
      "source": [
        "epochs_train = 11 # set small when debugging\n",
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_FC(size, lr=0.001, epsilon=0.1, memory_size=2000, batch_size=32)\n",
        "train(agent, env, epochs_train, prefix='fc_train')\n",
        "HTML(display_videos('fc_train10.mp4'))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4b15c03574f74cc8a455fa2b712bccb2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=11), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 0/11, loss 0.0034, win/lose count 4.5/7.0 (-2.5)\n",
            "Epoch 1/11, loss 0.0169, win/lose count 3.5/3.0 (0.5)\n",
            "Epoch 2/11, loss 0.0029, win/lose count 4.0/3.0 (1.0)\n",
            "Epoch 3/11, loss 0.0029, win/lose count 4.0/2.0 (2.0)\n",
            "Epoch 4/11, loss 0.0002, win/lose count 6.0/5.0 (1.0)\n",
            "Epoch 5/11, loss 0.0101, win/lose count 5.0/2.0 (3.0)\n",
            "Epoch 6/11, loss 0.0136, win/lose count 2.5/1.0 (1.5)\n",
            "Epoch 7/11, loss 0.0031, win/lose count 6.0/2.0 (4.0)\n",
            "Epoch 8/11, loss 0.0131, win/lose count 3.5/3.0 (0.5)\n",
            "Epoch 9/11, loss 0.0112, win/lose count 7.0/3.0 (4.0)\n",
            "Epoch 10/11, loss 0.0011, win/lose count 4.0/0 (4.0)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-M9Y_YtYN84l"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 8__ Implement the DQN training algorithm using a CNN (for example, 2 convolutional layers and one final fully connected layer)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bZ03CPRpN84n",
        "colab": {}
      },
      "source": [
        "class DQN_CNN(DQN):\n",
        "    def __init__(self, *args, lr=0.1, n_state=2, **kwargs):\n",
        "        super(DQN_CNN, self).__init__(*args, **kwargs)\n",
        "        \n",
        "        self.n_state = n_state\n",
        "        ###### FILL IN\n",
        "        #create model\n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(16, kernel_size=2, activation='relu', input_shape=(5, 5, n_state)))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Conv2D(32, kernel_size=2, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(256, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4, activation=None))\n",
        "        \n",
        "        model.compile(adam(lr=lr), \"mse\")\n",
        "        self.model = model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "collapsed": true,
        "id": "WaoXcuzWN84v",
        "outputId": "5e1eaa9c-5485-41f2-eb70-9e8b9ff43162",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529,
          "referenced_widgets": [
            "599c4fd3381f41179b775ca279adcd70",
            "d7f756dbd71144ad98b85c72d855454e",
            "80b4470eceaf428889e858c9b8c79896",
            "4fd898bf1a0348a594d7c97695e5c180",
            "31fb4461baf84626b9675a28761a350e",
            "7cca43208bcc4174992875a13c3f11e0",
            "250e1d09f2904415acc0c4f2c2785ea2",
            "f9e24a9b7d994c4297acb7c2f46890d2"
          ]
        }
      },
      "source": [
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_CNN(size, lr=0.1, epsilon=0.1, memory_size=2000, batch_size=32)\n",
        "train(agent, env, epochs_train, prefix='cnn_train')\n",
        "HTML(display_videos('cnn_train10.mp4'))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "599c4fd3381f41179b775ca279adcd70",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=11), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/11, loss 0.0094, win/lose count 2.5/4.0 (-1.5)\n",
            "Epoch 1/11, loss 0.0077, win/lose count 4.0/3.0 (1.0)\n",
            "Epoch 2/11, loss 0.0195, win/lose count 4.0/8.0 (-4.0)\n",
            "Epoch 3/11, loss 0.0098, win/lose count 8.5/8.0 (0.5)\n",
            "Epoch 4/11, loss 0.004, win/lose count 4.5/10.0 (-5.5)\n",
            "Epoch 5/11, loss 0.0101, win/lose count 10.0/17.0 (-7.0)\n",
            "Epoch 6/11, loss 0.0123, win/lose count 7.0/10.0 (-3.0)\n",
            "Epoch 7/11, loss 0.0126, win/lose count 4.5/12.0 (-7.5)\n",
            "Epoch 8/11, loss 0.0009, win/lose count 7.0/6.0 (1.0)\n",
            "Epoch 9/11, loss 0.021, win/lose count 7.5/11.0 (-3.5)\n",
            "Epoch 10/11, loss 0.0087, win/lose count 13.0/10.0 (3.0)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4SKJqwY4N843"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 9__ Test both algorithms and compare their performances. Which issue(s) do you observe? Observe also different behaviors by changing the temperature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_IEVjDaCN844",
        "colab": {}
      },
      "source": [
        "### initialize env \n",
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "\n",
        "### parameters\n",
        "epochs_test = 11\n",
        "\n",
        "### test CNN\n",
        "print('Test of the CNN')\n",
        "agent_cnn = DQN_CNN(size, lr=0.1, epsilon=0.1, memory_size=2000, batch_size=32)\n",
        "agent_cnn.load(name_weights='cnn_trainmodel.h5', name_model='cnn_trainmodel.json')\n",
        "test(agent_cnn, env, epochs_test, prefix='cnn_test')\n",
        "\n",
        "### test FC\n",
        "print('Test of the FC')\n",
        "agent_fc = DQN_FC(size, lr=0.1, epsilon=0.1, memory_size=2000, batch_size=32)\n",
        "agent_fc.load(name_weights='fc_trainmodel.h5', name_model='fc_trainmodel.json')\n",
        "test(agent_fc,env, epochs_test, prefix='fc_test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a8DQ5E13N84-",
        "colab": {}
      },
      "source": [
        "HTML(display_videos('cnn_test10.mp4'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vh7KbuEJN85F",
        "colab": {}
      },
      "source": [
        "HTML(display_videos('fc_test10.mp4'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mcilvdV0N85M"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HAlulF8bN85P"
      },
      "source": [
        "***\n",
        "\n",
        "The algorithm tends to not explore the map which can be an issue. We propose two ideas in order to encourage exploration:\n",
        "1. Incorporating a decreasing $\\epsilon$-greedy exploration. You can use the method ```set_epsilon```\n",
        "2. Append via the environment a new state that describes if a cell has been visited or not\n",
        "\n",
        "***\n",
        "__Question 10__ Design a new ```train_explore``` function and environment class ```EnvironmentExploring``` to tackle the issue of exploration.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CFgg4J__N85Q",
        "colab": {}
      },
      "source": [
        "def set_epsilon(epsilon, epoch, threshold=0.1):\n",
        "    temp = epsilon * ((epoch + 1) / (epoch + 2))\n",
        "    if temp < threshold:\n",
        "        return threshold\n",
        "    else:\n",
        "        return temp\n",
        "\n",
        "def train_explore(agent, env, epoch, prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "    agent.epsilon = 1.0\n",
        "\n",
        "    for e in tqdm.tqdm_notebook(range(epoch)):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "\n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "        \n",
        "        # update the exploration parameter (epsilon)\n",
        "        agent.epsilon = set_epsilon(agent.epsilon, e) \n",
        "\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            if prefix == 'cnn_train_explore':\n",
        "                action = agent.learned_act(state.flatten().reshape(1, 5, 5, 3)) # take action with the agent\n",
        "            else:\n",
        "                return np.nan\n",
        " \n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action, train=True)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose - reward\n",
        "\n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over, prefix)\n",
        "\n",
        "        # Save as a mp4\n",
        "        if e % 10 == 0:\n",
        "            env.draw(prefix + str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win - lose\n",
        "\n",
        "        print(f\"Epoch {e}/{epoch}, loss {round(np.float64(loss), 4)}, win/lose count {win}/{lose} ({win - lose})\")\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')\n",
        "        \n",
        "class EnvironmentExploring(object):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        \n",
        "        self.env = Environment(grid_size=size, max_time=max_time, temperature=temperature)\n",
        "        self.malus_position = np.zeros((grid_size, grid_size)) # places we already visited\n",
        "        \n",
        "    def act(self, action, train=True):\n",
        "            \n",
        "        ### first update then env  \n",
        "        state, reward, game_over = self.env.act(action)\n",
        "        \n",
        "        ### get malus if we already visited (x, y), only in train mode\n",
        "        if train:\n",
        "            malus_already_visited = - self.malus_position[self.env.x, self.env.y]\n",
        "        else:\n",
        "            malus_already_visited = 0\n",
        "            \n",
        "        ### update the malus_position array\n",
        "        self.malus_position[self.env.x, self.env.y] = 0.1\n",
        "\n",
        "        ### finally we update the reward by considering the malus_position score\n",
        "        reward += malus_already_visited\n",
        "    \n",
        "        \n",
        "        ### 3-feature state instead of 2\n",
        "        malus_position_visible = self.malus_position[self.env.x - 2:self.env.x + 3, self.env.y - 2:self.env.y + 3]\n",
        "        state = np.concatenate((malus_position_visible.reshape(5, 5, 1), state), axis=2)\n",
        "        \n",
        "        return state, reward, game_over\n",
        "    \n",
        "    def draw(self, e):\n",
        "        self.env.draw(e)\n",
        "    \n",
        "    def reset(self):\n",
        "        \n",
        "        ### call the Environment reset function\n",
        "        state = self.env.reset()\n",
        "        \n",
        "        ### reset the malus_position array\n",
        "        self.malus_position = np.zeros((self.env.grid_size, self.env.grid_size))\n",
        "        \n",
        "        ### 3-feature state instead of 2\n",
        "        malus_position_visible = self.malus_position[self.env.x - 2:self.env.x + 3, self.env.y - 2:self.env.y + 3]\n",
        "        state = np.concatenate((malus_position_visible.reshape(5, 5, 1), state), axis=2)\n",
        "        \n",
        "        return state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_F3lrnywN85V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 699,
          "referenced_widgets": [
            "f9a1e45c96e44ebe94d079108c6ab428",
            "0cc050f66a0b4b08a12ff404a6a689fa",
            "522d456c9df0421b9129887e8badc1a9",
            "05e35b38341744e3abd7f0fddf120392",
            "9ad75421d67f435c935b823f3ef418bd",
            "e1e349338807414d89804c379e5d5e49",
            "52af348165b94a31b30303270dc29b7a",
            "cb57c1f4dbfe4f3abd06994e7414b176"
          ]
        },
        "outputId": "ad7499c0-9a91-447e-f538-851a8e49c3d8"
      },
      "source": [
        "# Training\n",
        "epochs_train = 21\n",
        "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_CNN(size, lr=.001, epsilon=0.1, memory_size=2000, batch_size=32, n_state=3)\n",
        "train_explore(agent, env, epochs_train, prefix='cnn_train_explore')\n",
        "HTML(display_videos('cnn_train_explore10.mp4'))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f9a1e45c96e44ebe94d079108c6ab428",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=21), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/21, loss 0.014, win/lose count 10.5/23.700000000000088 (-13.200000000000088)\n",
            "Epoch 1/21, loss 0.0227, win/lose count 6.5/27.500000000000085 (-21.000000000000085)\n",
            "Epoch 2/21, loss 0.0162, win/lose count 6.5/25.10000000000011 (-18.60000000000011)\n",
            "Epoch 3/21, loss 0.0164, win/lose count 13.5/23.50000000000006 (-10.00000000000006)\n",
            "Epoch 4/21, loss 0.0144, win/lose count 16.0/19.30000000000001 (-3.3000000000000114)\n",
            "Epoch 5/21, loss 0.0165, win/lose count 15.0/20.500000000000007 (-5.500000000000007)\n",
            "Epoch 6/21, loss 0.0362, win/lose count 20.0/14.699999999999978 (5.300000000000022)\n",
            "Epoch 7/21, loss 0.014, win/lose count 21.5/17.79999999999998 (3.7000000000000206)\n",
            "Epoch 8/21, loss 0.0243, win/lose count 24.5/13.799999999999972 (10.700000000000028)\n",
            "Epoch 9/21, loss 0.0138, win/lose count 10.5/18.90000000000001 (-8.40000000000001)\n",
            "Epoch 10/21, loss 0.0151, win/lose count 24.0/14.79999999999997 (9.20000000000003)\n",
            "Epoch 11/21, loss 0.0242, win/lose count 23.5/15.999999999999973 (7.500000000000027)\n",
            "Epoch 12/21, loss 0.0195, win/lose count 28.5/16.79999999999999 (11.70000000000001)\n",
            "Epoch 13/21, loss 0.034, win/lose count 24.5/14.499999999999966 (10.000000000000034)\n",
            "Epoch 14/21, loss 0.0283, win/lose count 18.5/25.200000000000035 (-6.700000000000035)\n",
            "Epoch 15/21, loss 0.0165, win/lose count 27.0/16.499999999999986 (10.500000000000014)\n",
            "Epoch 16/21, loss 0.0475, win/lose count 22.5/26.80000000000009 (-4.3000000000000895)\n",
            "Epoch 17/21, loss 0.0232, win/lose count 22.5/23.80000000000005 (-1.3000000000000504)\n",
            "Epoch 18/21, loss 0.0429, win/lose count 28.5/20.40000000000003 (8.09999999999997)\n",
            "Epoch 19/21, loss 0.0218, win/lose count 14.0/29.20000000000007 (-15.20000000000007)\n",
            "Epoch 20/21, loss 0.0193, win/lose count 22.0/27.30000000000004 (-5.30000000000004)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-8BYes-SN85b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "outputId": "f9677e6c-ab55-4d56-ae15-cbffcd73fdc9"
      },
      "source": [
        "# Evaluation\n",
        "test(agent, env, epochs_test, prefix='cnn_test_explore')\n",
        "HTML(display_videos('cnn_test_explore9.mp4'))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, win/lose count 15.5/11.0, average score (4.5)\n",
            "Epoch 1, win/lose count 26.0/8.0, average score (11.25)\n",
            "Epoch 2, win/lose count 25.0/7.0, average score (13.5)\n",
            "Epoch 3, win/lose count 18.5/10.0, average score (12.25)\n",
            "Epoch 4, win/lose count 18.0/5.0, average score (12.4)\n",
            "Epoch 5, win/lose count 20.5/5.0, average score (12.92)\n",
            "Epoch 6, win/lose count 18.0/6.0, average score (12.79)\n",
            "Epoch 7, win/lose count 27.5/10.0, average score (13.38)\n",
            "Epoch 8, win/lose count 15.5/6.0, average score (12.94)\n",
            "Epoch 9, win/lose count 18.0/8.0, average score (12.65)\n",
            "Final score: 12.65\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4vAQNfIfN85h"
      },
      "source": [
        "***\n",
        "***\n",
        "__BONUS question__ Use the expert DQN from the previous question to generate some winning games. Train a model that mimicks its behavior. Compare the performances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rFRZBGW4N85i"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HutWDrV5N85k"
      },
      "source": [
        "***"
      ]
    }
  ]
}